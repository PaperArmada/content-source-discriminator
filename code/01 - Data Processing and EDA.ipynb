{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "358e6191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5c84d8",
   "metadata": {},
   "source": [
    "### Pull in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e91baf79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1093, 5), (1097, 5))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tech_support = pd.read_csv('../data/1646083584_TalesFromTechSupport.csv')\n",
    "retail = pd.read_csv('../data/1646083610_TalesFromRetail.csv')\n",
    "tech_support.shape, retail.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e5a95f",
   "metadata": {},
   "source": [
    "### Check Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4287000e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SonDontPlay</td>\n",
       "      <td>\"Where is the router?\"</td>\n",
       "      <td>A General Officer calls in for urgent tech sup...</td>\n",
       "      <td>talesfromtechsupport</td>\n",
       "      <td>1638946522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talbourne</td>\n",
       "      <td>With users like this...</td>\n",
       "      <td>I'll be staying at this company for a long tim...</td>\n",
       "      <td>talesfromtechsupport</td>\n",
       "      <td>1638904166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>edhands</td>\n",
       "      <td>Math...what a concept</td>\n",
       "      <td>Back in 2009, our company purchased a horribly...</td>\n",
       "      <td>talesfromtechsupport</td>\n",
       "      <td>1629488107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12altoids34</td>\n",
       "      <td>I'll have you know I've been working on comput...</td>\n",
       "      <td>Thats how the call started. \\n\\nThen she went ...</td>\n",
       "      <td>talesfromtechsupport</td>\n",
       "      <td>1623803260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gingrpenguin</td>\n",
       "      <td>We need you to tell us our current password. N...</td>\n",
       "      <td>For backstory i worked for a small tech compan...</td>\n",
       "      <td>talesfromtechsupport</td>\n",
       "      <td>1623769022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         author                                              title  \\\n",
       "0   SonDontPlay                             \"Where is the router?\"   \n",
       "1     talbourne                            With users like this...   \n",
       "2       edhands                              Math...what a concept   \n",
       "3   12altoids34  I'll have you know I've been working on comput...   \n",
       "4  Gingrpenguin  We need you to tell us our current password. N...   \n",
       "\n",
       "                                            selftext             subreddit  \\\n",
       "0  A General Officer calls in for urgent tech sup...  talesfromtechsupport   \n",
       "1  I'll be staying at this company for a long tim...  talesfromtechsupport   \n",
       "2  Back in 2009, our company purchased a horribly...  talesfromtechsupport   \n",
       "3  Thats how the call started. \\n\\nThen she went ...  talesfromtechsupport   \n",
       "4  For backstory i worked for a small tech compan...  talesfromtechsupport   \n",
       "\n",
       "   created_utc  \n",
       "0   1638946522  \n",
       "1   1638904166  \n",
       "2   1629488107  \n",
       "3   1623803260  \n",
       "4   1623769022  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tech_support.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2d94399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author         0\n",
       "title          0\n",
       "selftext       0\n",
       "subreddit      0\n",
       "created_utc    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tech_support.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0495004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MattyDGames</td>\n",
       "      <td>Your know card doesn’t work? Let’s grab all th...</td>\n",
       "      <td>Ok ok, today I had a customer come in with a c...</td>\n",
       "      <td>TalesFromRetail</td>\n",
       "      <td>1638923563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MissMissieFatCat</td>\n",
       "      <td>Woman proves herself wrong and storms out of s...</td>\n",
       "      <td>I work in a family owned pet food/supply store...</td>\n",
       "      <td>TalesFromRetail</td>\n",
       "      <td>1623770945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Knever</td>\n",
       "      <td>Coworkers try to steal $200 worth of groceries...</td>\n",
       "      <td>I worked at a grocery store with a guy who, on...</td>\n",
       "      <td>TalesFromRetail</td>\n",
       "      <td>1623707257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mr_jon3s</td>\n",
       "      <td>Moves parking cone gets mad that I yelled at h...</td>\n",
       "      <td>Having some work done on the parking lot so we...</td>\n",
       "      <td>TalesFromRetail</td>\n",
       "      <td>1623594705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pessimist_kitty</td>\n",
       "      <td>Getting real tired of people thinking we're ma...</td>\n",
       "      <td>This just happened this morning and I had to s...</td>\n",
       "      <td>TalesFromRetail</td>\n",
       "      <td>1614891256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author                                              title  \\\n",
       "0       MattyDGames  Your know card doesn’t work? Let’s grab all th...   \n",
       "1  MissMissieFatCat  Woman proves herself wrong and storms out of s...   \n",
       "2            Knever  Coworkers try to steal $200 worth of groceries...   \n",
       "3          Mr_jon3s  Moves parking cone gets mad that I yelled at h...   \n",
       "4   pessimist_kitty  Getting real tired of people thinking we're ma...   \n",
       "\n",
       "                                            selftext        subreddit  \\\n",
       "0  Ok ok, today I had a customer come in with a c...  TalesFromRetail   \n",
       "1  I work in a family owned pet food/supply store...  TalesFromRetail   \n",
       "2  I worked at a grocery store with a guy who, on...  TalesFromRetail   \n",
       "3  Having some work done on the parking lot so we...  TalesFromRetail   \n",
       "4  This just happened this morning and I had to s...  TalesFromRetail   \n",
       "\n",
       "   created_utc  \n",
       "0   1638923563  \n",
       "1   1623770945  \n",
       "2   1623707257  \n",
       "3   1623594705  \n",
       "4   1614891256  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retail.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64accf87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author         0\n",
       "title          0\n",
       "selftext       0\n",
       "subreddit      0\n",
       "created_utc    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retail.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57908e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2190, 5)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = tech_support.append(retail, ignore_index=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedbe32d",
   "metadata": {},
   "source": [
    "### Select Positive Class\n",
    "\n",
    "TalesFromTechSupport will be my positive class for these models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28aed63f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SonDontPlay</td>\n",
       "      <td>\"Where is the router?\"</td>\n",
       "      <td>A General Officer calls in for urgent tech sup...</td>\n",
       "      <td>1</td>\n",
       "      <td>1638946522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talbourne</td>\n",
       "      <td>With users like this...</td>\n",
       "      <td>I'll be staying at this company for a long tim...</td>\n",
       "      <td>1</td>\n",
       "      <td>1638904166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>edhands</td>\n",
       "      <td>Math...what a concept</td>\n",
       "      <td>Back in 2009, our company purchased a horribly...</td>\n",
       "      <td>1</td>\n",
       "      <td>1629488107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12altoids34</td>\n",
       "      <td>I'll have you know I've been working on comput...</td>\n",
       "      <td>Thats how the call started. \\n\\nThen she went ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1623803260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gingrpenguin</td>\n",
       "      <td>We need you to tell us our current password. N...</td>\n",
       "      <td>For backstory i worked for a small tech compan...</td>\n",
       "      <td>1</td>\n",
       "      <td>1623769022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         author                                              title  \\\n",
       "0   SonDontPlay                             \"Where is the router?\"   \n",
       "1     talbourne                            With users like this...   \n",
       "2       edhands                              Math...what a concept   \n",
       "3   12altoids34  I'll have you know I've been working on comput...   \n",
       "4  Gingrpenguin  We need you to tell us our current password. N...   \n",
       "\n",
       "                                            selftext  subreddit  created_utc  \n",
       "0  A General Officer calls in for urgent tech sup...          1   1638946522  \n",
       "1  I'll be staying at this company for a long tim...          1   1638904166  \n",
       "2  Back in 2009, our company purchased a horribly...          1   1629488107  \n",
       "3  Thats how the call started. \\n\\nThen she went ...          1   1623803260  \n",
       "4  For backstory i worked for a small tech compan...          1   1623769022  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subreddit'] = df['subreddit'].replace({'TalesFromRetail': 0, 'talesfromtechsupport': 1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8475403c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.500913\n",
       "1    0.499087\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subreddit'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41257bb",
   "metadata": {},
   "source": [
    "Nice even split of data, providing good grounds for evaluation of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cf909d",
   "metadata": {},
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eed5f933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Breakfast Hour lecture https://git.generalassemb.ly/DSIR-0124/Breakfast-Hour/blob/master/06-week/MON%20-%20S%20-%20NLP%20Practice.ipynb\n",
    "\n",
    "def remove_html(content):\n",
    "    '''function to remove html and lowercase all text'''\n",
    "    \n",
    "    no_html = BeautifulSoup(content).text\n",
    "    # removes html\n",
    "    \n",
    "    lower_case = no_html.lower()\n",
    "    # lowercase all text\n",
    "    \n",
    "    return lower_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "705ca60e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>clean_selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SonDontPlay</td>\n",
       "      <td>\"Where is the router?\"</td>\n",
       "      <td>A General Officer calls in for urgent tech sup...</td>\n",
       "      <td>1</td>\n",
       "      <td>1638946522</td>\n",
       "      <td>\"where is the router?\"</td>\n",
       "      <td>a general officer calls in for urgent tech sup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talbourne</td>\n",
       "      <td>With users like this...</td>\n",
       "      <td>I'll be staying at this company for a long tim...</td>\n",
       "      <td>1</td>\n",
       "      <td>1638904166</td>\n",
       "      <td>with users like this...</td>\n",
       "      <td>i'll be staying at this company for a long tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>edhands</td>\n",
       "      <td>Math...what a concept</td>\n",
       "      <td>Back in 2009, our company purchased a horribly...</td>\n",
       "      <td>1</td>\n",
       "      <td>1629488107</td>\n",
       "      <td>math...what a concept</td>\n",
       "      <td>back in 2009, our company purchased a horribly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12altoids34</td>\n",
       "      <td>I'll have you know I've been working on comput...</td>\n",
       "      <td>Thats how the call started. \\n\\nThen she went ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1623803260</td>\n",
       "      <td>i'll have you know i've been working on comput...</td>\n",
       "      <td>thats how the call started. \\n\\nthen she went ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gingrpenguin</td>\n",
       "      <td>We need you to tell us our current password. N...</td>\n",
       "      <td>For backstory i worked for a small tech compan...</td>\n",
       "      <td>1</td>\n",
       "      <td>1623769022</td>\n",
       "      <td>we need you to tell us our current password. n...</td>\n",
       "      <td>for backstory i worked for a small tech compan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         author                                              title  \\\n",
       "0   SonDontPlay                             \"Where is the router?\"   \n",
       "1     talbourne                            With users like this...   \n",
       "2       edhands                              Math...what a concept   \n",
       "3   12altoids34  I'll have you know I've been working on comput...   \n",
       "4  Gingrpenguin  We need you to tell us our current password. N...   \n",
       "\n",
       "                                            selftext  subreddit  created_utc  \\\n",
       "0  A General Officer calls in for urgent tech sup...          1   1638946522   \n",
       "1  I'll be staying at this company for a long tim...          1   1638904166   \n",
       "2  Back in 2009, our company purchased a horribly...          1   1629488107   \n",
       "3  Thats how the call started. \\n\\nThen she went ...          1   1623803260   \n",
       "4  For backstory i worked for a small tech compan...          1   1623769022   \n",
       "\n",
       "                                         clean_title  \\\n",
       "0                             \"where is the router?\"   \n",
       "1                            with users like this...   \n",
       "2                              math...what a concept   \n",
       "3  i'll have you know i've been working on comput...   \n",
       "4  we need you to tell us our current password. n...   \n",
       "\n",
       "                                      clean_selftext  \n",
       "0  a general officer calls in for urgent tech sup...  \n",
       "1  i'll be staying at this company for a long tim...  \n",
       "2  back in 2009, our company purchased a horribly...  \n",
       "3  thats how the call started. \\n\\nthen she went ...  \n",
       "4  for backstory i worked for a small tech compan...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_title'] = df['title'].apply(remove_html)\n",
    "df['clean_selftext'] = df['selftext'].apply(remove_html)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a292c6e",
   "metadata": {},
   "source": [
    "### Separate Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d484297",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = df['clean_title']\n",
    "X_st = df['clean_selftext']\n",
    "y = df['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "03d5de71",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t, X_test_t, y_train, y_test = train_test_split(X_t, y, random_state=42, stratify=y)\n",
    "# match up \n",
    "X_train_st = X_st[X_train_t.index]\n",
    "X_test_st = X_st[X_test_t.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bba3bab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_st.index == X_train_t.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3a12b8",
   "metadata": {},
   "source": [
    "### Preliminary Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "735258a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('logreg', LogisticRegression(max_iter=1000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c04c2d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                ('logreg', LogisticRegression(max_iter=1000))])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start with a model using the title and default parameters\n",
    "\n",
    "pipe.fit(X_train_t, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "fcdfa0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.702801461632156\n",
      "Test Score: 0.6952554744525548\n",
      "Cross-Val Score: 0.7442249240121581\n"
     ]
    }
   ],
   "source": [
    "print('Train Score:', pipe.score(X_train_t, y_train))\n",
    "print('Test Score:', pipe.score(X_test_t, y_test))\n",
    "print('Cross-Val Score:', cross_val_score(pipe, X_train_t, y_train).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d22fdf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val = cross_val_score(pipe, X_train_t, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "33b6b64d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06951966850402047"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val.std()*3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89ba520",
   "metadata": {},
   "source": [
    "Very high variance seen in the model, with training data accurately predicting the subreddit 96% of the time with training data, but only 74% of the time with unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d6d54943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                ('logreg', LogisticRegression(max_iter=1000))])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see how selftext does\n",
    "\n",
    "pipe.fit(X_train_st, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "a6bc0955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.9926918392204629\n",
      "Test Score: 0.9397810218978102\n",
      "Cross-Val Score: 0.957975016680258\n"
     ]
    }
   ],
   "source": [
    "print('Train Score:', pipe.score(X_train_st, y_train))\n",
    "print('Test Score:', pipe.score(X_test_st, y_test))\n",
    "cross_val = cross_val_score(pipe, X_train_st, y_train)\n",
    "print('Cross-Val Score:', cross_val.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "2e35a1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Val Standard Deviation: 0.0138\n",
      "Accuracy range between: 0.92 and 1.00\n"
     ]
    }
   ],
   "source": [
    "sig_3 = cross_val.std()*3\n",
    "print('Cross-Val Standard Deviation:', '{:.4f}'.format(cross_val.std()))\n",
    "print('Accuracy range between:', '{:.2f}'.format(cross_val.mean() - sig_3), 'and', '{:.2f}'.format(cross_val.mean() + sig_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb2cece",
   "metadata": {},
   "source": [
    "Wow, much better. As expected, the volume of the text has a significant affect on performance. Still a bit of variance, but already the model is doing an excellent job predicting unseen data with 94% accuracy. We are overfitting a bit it seems, with 99% accuracy on the training data, so we may be able to squeeze some performance by stripping out some of the features (maybe with LASSO)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c3fe50a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2ba95459188>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Confusion Matrix\n",
    "ConfusionMatrixDisplay.from_estimator(pipe, X_test_st, y_test, cmap='hot', display_labels=('Not From Subreddit', 'From Subreddit'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a9269c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pipe.predict(X_test_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bae44268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       275\n",
      "           1       0.94      0.94      0.94       273\n",
      "\n",
      "    accuracy                           0.94       548\n",
      "   macro avg       0.94      0.94      0.94       548\n",
      "weighted avg       0.94      0.94      0.94       548\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ed5c74",
   "metadata": {},
   "source": [
    "This basic logistic regression model outperforms the baseline (50% accuracy when guessing all posts are not from the target subreddit) with 94% accuracy, and is balanced in its false positive/false negative rates with 94% precision and 94% recall rates. We already have a solid model for predicting post origin based on these results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ceac60",
   "metadata": {},
   "source": [
    "### Tune Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12faf437",
   "metadata": {},
   "source": [
    "I'm going to start by taking a look at what the model's top features based on coefficient magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e227b92c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.91402767e-03, -6.83126089e-02, -2.37074410e-08, ...,\n",
       "       -8.46863996e-04, -1.55397906e-02, -8.46863996e-04])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# approach found at https://stackoverflow.com/questions/43856280/return-coefficients-from-pipeline-object-in-sklearn\n",
    "vectorizer = pipe.named_steps['cvec']\n",
    "classifier = pipe.named_steps['logreg']\n",
    "coefs_st = classifier.coef_[0]\n",
    "coefs_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d8fe8497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19713,)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs_st.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c035d9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_st = vectorizer.get_feature_names_out()\n",
    "features_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cca00062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19713,)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_st.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "da67a81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_coefs = pd.Series(index=features_st, data=coefs_st)\n",
    "sorted_features = feature_coefs.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d18d1f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tech         0.842383\n",
       "support      0.832082\n",
       "computer     0.750193\n",
       "user         0.555967\n",
       "call         0.498199\n",
       "laptop       0.484596\n",
       "power        0.475655\n",
       "email        0.469996\n",
       "calls        0.448273\n",
       "desk         0.423087\n",
       "computers    0.418817\n",
       "office       0.402232\n",
       "new          0.383437\n",
       "pc           0.369927\n",
       "removed      0.362786\n",
       "router       0.356202\n",
       "ticket       0.352710\n",
       "crosspost    0.349402\n",
       "again        0.347519\n",
       "from         0.345958\n",
       "dtype: float64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_features.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718b9ac4",
   "metadata": {},
   "source": [
    "Notably, \"computer\" and \"computers\" both make it onto the list (which makes sense as a dead giveaway...) as separate items; I'd be interested in seeing how a stemmer impacts performance. And then the words \"tech\" and \"support\" being the top words is certainly no surprise. I hadn't originally considered that \"office\" would be strongly tied to tech support, but obviously retail business is not typically conducted in an office, so I feel a little silly for not having identified that for myself beforehand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5c2d67b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "were       -0.266657\n",
       "gift       -0.269113\n",
       "sir        -0.283790\n",
       "came       -0.284316\n",
       "come       -0.287723\n",
       "them       -0.294136\n",
       "customer   -0.296085\n",
       "sale       -0.298438\n",
       "then       -0.307782\n",
       "item       -0.320667\n",
       "items      -0.343231\n",
       "card       -0.349551\n",
       "bag        -0.371315\n",
       "woman      -0.371769\n",
       "register   -0.376236\n",
       "cashier    -0.381926\n",
       "counter    -0.397605\n",
       "retail     -0.413051\n",
       "order      -0.416084\n",
       "store      -1.187742\n",
       "dtype: float64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_features.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a8f521",
   "metadata": {},
   "source": [
    "The words shown here point away from the target subreddit, and towards our opposing subreddit, \"TalesFromRetail\". It appears here as well that applying a stemmer could be useful, but otherwise most of the words seem to make sense. Some interesting standouts in \"then\" and \"were\" being in this list; curious to me that those would be used more frequently in retail relative to tech support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aef3c716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('cvec', CountVectorizer()),\n",
       "  ('logreg', LogisticRegression(max_iter=1000))],\n",
       " 'verbose': False,\n",
       " 'cvec': CountVectorizer(),\n",
       " 'logreg': LogisticRegression(max_iter=1000),\n",
       " 'cvec__analyzer': 'word',\n",
       " 'cvec__binary': False,\n",
       " 'cvec__decode_error': 'strict',\n",
       " 'cvec__dtype': numpy.int64,\n",
       " 'cvec__encoding': 'utf-8',\n",
       " 'cvec__input': 'content',\n",
       " 'cvec__lowercase': True,\n",
       " 'cvec__max_df': 1.0,\n",
       " 'cvec__max_features': None,\n",
       " 'cvec__min_df': 1,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__preprocessor': None,\n",
       " 'cvec__stop_words': None,\n",
       " 'cvec__strip_accents': None,\n",
       " 'cvec__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'cvec__tokenizer': None,\n",
       " 'cvec__vocabulary': None,\n",
       " 'logreg__C': 1.0,\n",
       " 'logreg__class_weight': None,\n",
       " 'logreg__dual': False,\n",
       " 'logreg__fit_intercept': True,\n",
       " 'logreg__intercept_scaling': 1,\n",
       " 'logreg__l1_ratio': None,\n",
       " 'logreg__max_iter': 1000,\n",
       " 'logreg__multi_class': 'auto',\n",
       " 'logreg__n_jobs': None,\n",
       " 'logreg__penalty': 'l2',\n",
       " 'logreg__random_state': None,\n",
       " 'logreg__solver': 'lbfgs',\n",
       " 'logreg__tol': 0.0001,\n",
       " 'logreg__verbose': 0,\n",
       " 'logreg__warm_start': False}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1812611c",
   "metadata": {},
   "source": [
    "Okay, let's see how cutting down the number of words using a stemmer and dropping stop words in the vectorizer, and using LASSO with the logistic regression, affects things. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "62249f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# approach from https://git.generalassemb.ly/DSIR-0124/Breakfast-Hour/blob/master/06-week/MON%20-%20S%20-%20NLP%20Practice.ipynb\n",
    "\n",
    "def stem_content(content):\n",
    "    p_stemmer = PorterStemmer()\n",
    "    split_content = content.split(' ')\n",
    "    return [p_stemmer.stem(word) for word in split_content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "affdb274",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\musou\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "C:\\Users\\musou\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "C:\\Users\\musou\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "C:\\Users\\musou\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "C:\\Users\\musou\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "C:\\Users\\musou\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "C:\\Users\\musou\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "C:\\Users\\musou\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "C:\\Users\\musou\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  % sorted(inconsistent)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\musou\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "C:\\Users\\musou\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "C:\\Users\\musou\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "C:\\Users\\musou\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "C:\\Users\\musou\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "C:\\Users\\musou\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  % sorted(inconsistent)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to complete: 9 min, 41 seconds\n",
      "0.9549280895544519\n",
      "{'cvec__stop_words': 'english', 'cvec__tokenizer': None, 'logreg__C': 0.7, 'logreg__penalty': 'l1', 'logreg__solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "t_start = int(time.time())\n",
    "\n",
    "np.random.seed(42)\n",
    "params1 = {\n",
    "    'cvec__tokenizer': [None, stem_content],\n",
    "    'cvec__stop_words': [None, 'english'],\n",
    "    'logreg__penalty': ['l1'], # LASSO regularization\n",
    "    'logreg__solver': ['liblinear'], # solver that handles LASSO\n",
    "    'logreg__C': [1.0, .7, .4]\n",
    "}\n",
    "\n",
    "gs1 = GridSearchCV(pipe, params1)\n",
    "gs1.fit(X_train_st, y_train)\n",
    "\n",
    "t_finish = int(time.time())\n",
    "t_delta = t_finish - t_start\n",
    "\n",
    "print(f'Time to complete: {t_delta // 60} min, {t_delta % 60} seconds')\n",
    "print(gs1.best_score_)\n",
    "print(gs1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "4daf9a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.9920828258221681\n",
      "Test Score: 0.9525547445255474\n",
      "Cross-Val Score: 0.9549280895544519\n"
     ]
    }
   ],
   "source": [
    "print('Train Score:', gs1.score(X_train_st, y_train))\n",
    "print('Test Score:', gs1.score(X_test_st, y_test))\n",
    "print('Cross-Val Score:', gs1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "cb5be603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2ba9802dd08>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(gs1, X_test_st, y_test, cmap='hot', display_labels=('Not From Subreddit', 'From Subreddit'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "200c511a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_cvec__stop_words</th>\n",
       "      <th>param_cvec__tokenizer</th>\n",
       "      <th>param_logreg__C</th>\n",
       "      <th>param_logreg__penalty</th>\n",
       "      <th>param_logreg__solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.620963</td>\n",
       "      <td>0.011011</td>\n",
       "      <td>0.130335</td>\n",
       "      <td>0.003037</td>\n",
       "      <td>english</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'cvec__stop_words': 'english', 'cvec__tokeniz...</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.960486</td>\n",
       "      <td>0.948171</td>\n",
       "      <td>0.960366</td>\n",
       "      <td>0.948171</td>\n",
       "      <td>0.954928</td>\n",
       "      <td>0.005624</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.616761</td>\n",
       "      <td>0.009547</td>\n",
       "      <td>0.129357</td>\n",
       "      <td>0.004140</td>\n",
       "      <td>english</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'cvec__stop_words': 'english', 'cvec__tokeniz...</td>\n",
       "      <td>0.954407</td>\n",
       "      <td>0.963526</td>\n",
       "      <td>0.945122</td>\n",
       "      <td>0.960366</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.954928</td>\n",
       "      <td>0.006537</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.618787</td>\n",
       "      <td>0.019818</td>\n",
       "      <td>0.129939</td>\n",
       "      <td>0.004459</td>\n",
       "      <td>english</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'cvec__stop_words': 'english', 'cvec__tokeniz...</td>\n",
       "      <td>0.954407</td>\n",
       "      <td>0.960486</td>\n",
       "      <td>0.948171</td>\n",
       "      <td>0.957317</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.954320</td>\n",
       "      <td>0.004346</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.703402</td>\n",
       "      <td>0.015770</td>\n",
       "      <td>0.143528</td>\n",
       "      <td>0.006482</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'cvec__stop_words': None, 'cvec__tokenizer': ...</td>\n",
       "      <td>0.942249</td>\n",
       "      <td>0.948328</td>\n",
       "      <td>0.935976</td>\n",
       "      <td>0.966463</td>\n",
       "      <td>0.954268</td>\n",
       "      <td>0.949457</td>\n",
       "      <td>0.010463</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.703039</td>\n",
       "      <td>0.012355</td>\n",
       "      <td>0.144097</td>\n",
       "      <td>0.008094</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'cvec__stop_words': None, 'cvec__tokenizer': ...</td>\n",
       "      <td>0.942249</td>\n",
       "      <td>0.948328</td>\n",
       "      <td>0.932927</td>\n",
       "      <td>0.969512</td>\n",
       "      <td>0.954268</td>\n",
       "      <td>0.949457</td>\n",
       "      <td>0.012262</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "7       0.620963      0.011011         0.130335        0.003037   \n",
       "8       0.616761      0.009547         0.129357        0.004140   \n",
       "6       0.618787      0.019818         0.129939        0.004459   \n",
       "0       0.703402      0.015770         0.143528        0.006482   \n",
       "1       0.703039      0.012355         0.144097        0.008094   \n",
       "\n",
       "  param_cvec__stop_words param_cvec__tokenizer param_logreg__C  \\\n",
       "7                english                  None             0.7   \n",
       "8                english                  None             0.4   \n",
       "6                english                  None             1.0   \n",
       "0                   None                  None             1.0   \n",
       "1                   None                  None             0.7   \n",
       "\n",
       "  param_logreg__penalty param_logreg__solver  \\\n",
       "7                    l1            liblinear   \n",
       "8                    l1            liblinear   \n",
       "6                    l1            liblinear   \n",
       "0                    l1            liblinear   \n",
       "1                    l1            liblinear   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "7  {'cvec__stop_words': 'english', 'cvec__tokeniz...           0.957447   \n",
       "8  {'cvec__stop_words': 'english', 'cvec__tokeniz...           0.954407   \n",
       "6  {'cvec__stop_words': 'english', 'cvec__tokeniz...           0.954407   \n",
       "0  {'cvec__stop_words': None, 'cvec__tokenizer': ...           0.942249   \n",
       "1  {'cvec__stop_words': None, 'cvec__tokenizer': ...           0.942249   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "7           0.960486           0.948171           0.960366           0.948171   \n",
       "8           0.963526           0.945122           0.960366           0.951220   \n",
       "6           0.960486           0.948171           0.957317           0.951220   \n",
       "0           0.948328           0.935976           0.966463           0.954268   \n",
       "1           0.948328           0.932927           0.969512           0.954268   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "7         0.954928        0.005624                1  \n",
       "8         0.954928        0.006537                2  \n",
       "6         0.954320        0.004346                3  \n",
       "0         0.949457        0.010463                4  \n",
       "1         0.949457        0.012262                4  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# approach from https://git.generalassemb.ly/DSIR-0124/lesson-hyperparameters-gridsearch-and-pipelines/blob/master/starter-code.ipynb\n",
    "\n",
    "pd.DataFrame(gs1.cv_results_).sort_values('rank_test_score').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac17c03",
   "metadata": {},
   "source": [
    "Not much difference there, with the particular exception that english stop words significantly reduced the cross_val standard deviation. On our original model, we were seeing a standard deviation of around .014, and this new model more than halves that down to .006. This is great; the overall variance of our model is diminishing, even though we aren't yet seeing much affect on our train and test scores.\n",
    "\n",
    "Also of note, the Train score remains very close to perfect; I want to try and push that down away from overfitting and try to give some room to swap bias for variance (thinking that will bring the cross-val and test scores up along the way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "5d32de5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(stop_words='english')"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs1.best_estimator_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "2763c059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.7, max_iter=1000, penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs1.best_estimator_[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ff3d87",
   "metadata": {},
   "source": [
    "For our count vectorizor, stemming didn't appear to help much, but stop words certainly helped with variance. Next, I'd like to get a little better resolution on regularization strength values, and try to cut down features a bit more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "afef40fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to complete: 0 min, 33 seconds\n",
      "0.956145748387575\n",
      "{'cvec__stop_words': 'english', 'logreg__C': 0.6, 'logreg__penalty': 'l1', 'logreg__solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "t_start = int(time.time())\n",
    "\n",
    "np.random.seed(42)\n",
    "params2 = {\n",
    "#     'cvec__tokenizer': [None, stem_content], # tokenizer didn't seem to help\n",
    "    'cvec__stop_words': ['english'], # english stop words bought down our standard deviation considerably\n",
    "    'logreg__penalty': ['l1'], # LASSO regularization\n",
    "    'logreg__solver': ['liblinear'], # solver that handles LASSO\n",
    "    'logreg__C': [.8, .7, .6, .5, .4, .3, .2, .1]\n",
    "}\n",
    "\n",
    "gs2 = GridSearchCV(pipe, params2)\n",
    "gs2.fit(X_train_st, y_train)\n",
    "\n",
    "t_finish = int(time.time())\n",
    "t_delta = t_finish - t_start\n",
    "\n",
    "print(f'Time to complete: {t_delta // 60} min, {t_delta % 60} seconds')\n",
    "print(gs2.best_score_)\n",
    "print(gs2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "9802c108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.9908647990255786\n",
      "Test Score: 0.9525547445255474\n",
      "Cross-Val Score: 0.956145748387575\n"
     ]
    }
   ],
   "source": [
    "print('Train Score:', gs2.score(X_train_st, y_train))\n",
    "print('Test Score:', gs2.score(X_test_st, y_test))\n",
    "print('Cross-Val Score:', gs2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "1a503ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2ba96d23408>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(gs2, X_test_st, y_test, cmap='hot', display_labels=('Not From Subreddit', 'From Subreddit'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "897897dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_cvec__stop_words</th>\n",
       "      <th>param_logreg__C</th>\n",
       "      <th>param_logreg__penalty</th>\n",
       "      <th>param_logreg__solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.662143</td>\n",
       "      <td>0.009502</td>\n",
       "      <td>0.141446</td>\n",
       "      <td>0.014434</td>\n",
       "      <td>english</td>\n",
       "      <td>0.6</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'cvec__stop_words': 'english', 'logreg__C': 0...</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.963526</td>\n",
       "      <td>0.948171</td>\n",
       "      <td>0.960366</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.956146</td>\n",
       "      <td>0.005689</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.660284</td>\n",
       "      <td>0.009097</td>\n",
       "      <td>0.142618</td>\n",
       "      <td>0.005246</td>\n",
       "      <td>english</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'cvec__stop_words': 'english', 'logreg__C': 0...</td>\n",
       "      <td>0.954407</td>\n",
       "      <td>0.960486</td>\n",
       "      <td>0.948171</td>\n",
       "      <td>0.960366</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.954930</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.671227</td>\n",
       "      <td>0.011355</td>\n",
       "      <td>0.144629</td>\n",
       "      <td>0.006419</td>\n",
       "      <td>english</td>\n",
       "      <td>0.7</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'cvec__stop_words': 'english', 'logreg__C': 0...</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.960486</td>\n",
       "      <td>0.948171</td>\n",
       "      <td>0.960366</td>\n",
       "      <td>0.948171</td>\n",
       "      <td>0.954928</td>\n",
       "      <td>0.005624</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.664808</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.145820</td>\n",
       "      <td>0.006421</td>\n",
       "      <td>english</td>\n",
       "      <td>0.4</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'cvec__stop_words': 'english', 'logreg__C': 0...</td>\n",
       "      <td>0.954407</td>\n",
       "      <td>0.960486</td>\n",
       "      <td>0.945122</td>\n",
       "      <td>0.960366</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.954320</td>\n",
       "      <td>0.005810</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.661031</td>\n",
       "      <td>0.005593</td>\n",
       "      <td>0.141836</td>\n",
       "      <td>0.004064</td>\n",
       "      <td>english</td>\n",
       "      <td>0.8</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'cvec__stop_words': 'english', 'logreg__C': 0...</td>\n",
       "      <td>0.954407</td>\n",
       "      <td>0.960486</td>\n",
       "      <td>0.945122</td>\n",
       "      <td>0.960366</td>\n",
       "      <td>0.948171</td>\n",
       "      <td>0.953710</td>\n",
       "      <td>0.006247</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "2       0.662143      0.009502         0.141446        0.014434   \n",
       "3       0.660284      0.009097         0.142618        0.005246   \n",
       "1       0.671227      0.011355         0.144629        0.006419   \n",
       "4       0.664808      0.030719         0.145820        0.006421   \n",
       "0       0.661031      0.005593         0.141836        0.004064   \n",
       "\n",
       "  param_cvec__stop_words param_logreg__C param_logreg__penalty  \\\n",
       "2                english             0.6                    l1   \n",
       "3                english             0.5                    l1   \n",
       "1                english             0.7                    l1   \n",
       "4                english             0.4                    l1   \n",
       "0                english             0.8                    l1   \n",
       "\n",
       "  param_logreg__solver                                             params  \\\n",
       "2            liblinear  {'cvec__stop_words': 'english', 'logreg__C': 0...   \n",
       "3            liblinear  {'cvec__stop_words': 'english', 'logreg__C': 0...   \n",
       "1            liblinear  {'cvec__stop_words': 'english', 'logreg__C': 0...   \n",
       "4            liblinear  {'cvec__stop_words': 'english', 'logreg__C': 0...   \n",
       "0            liblinear  {'cvec__stop_words': 'english', 'logreg__C': 0...   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "2           0.957447           0.963526           0.948171           0.960366   \n",
       "3           0.954407           0.960486           0.948171           0.960366   \n",
       "1           0.957447           0.960486           0.948171           0.960366   \n",
       "4           0.954407           0.960486           0.945122           0.960366   \n",
       "0           0.954407           0.960486           0.945122           0.960366   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "2           0.951220         0.956146        0.005689                1  \n",
       "3           0.951220         0.954930        0.004902                2  \n",
       "1           0.948171         0.954928        0.005624                3  \n",
       "4           0.951220         0.954320        0.005810                4  \n",
       "0           0.948171         0.953710        0.006247                5  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs2.cv_results_).sort_values('rank_test_score').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3099c62b",
   "metadata": {},
   "source": [
    "Okay, looks like we're starting to split hairs with the regularization strengths. Seeing solid performance with the top two grid searched models producing around 95.5% accuracy, with a standard deviation around .5%.  \n",
    "\n",
    "One last thing I'd like to try with this logistic regression model is to incorporate n-grams; I suspect that there are a number of word combinations that would be strong indicators for our subreddits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547f3a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start = int(time.time())\n",
    "\n",
    "np.random.seed(42)\n",
    "params3 = {\n",
    "    'cvec__stop_words': ['english'], # english stop words bought down our standard deviation considerably\n",
    "    'cvec__ngram_range': [(2,2), (1,2)] # explore two-word space\n",
    "    'logreg__penalty': ['l1'], # LASSO regularization\n",
    "    'logreg__solver': ['liblinear'], # solver that handles LASSO\n",
    "    'logreg__C': [.6, .55, .5] # exploring the space between the two previous best regularization strengths (assuming indepence from other params)\n",
    "}\n",
    "\n",
    "gs3 = GridSearchCV(pipe, params3)\n",
    "gs3.fit(X_train_st, y_train)\n",
    "\n",
    "t_finish = int(time.time())\n",
    "t_delta = t_finish - t_start\n",
    "\n",
    "print(f'Time to complete: {t_delta // 60} min, {t_delta % 60} seconds')\n",
    "print(gs3.best_score_)\n",
    "print(gs3.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
